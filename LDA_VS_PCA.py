# -*- coding: utf-8 -*-
"""Lab8ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PZgV_CUrgHRaksB1gzO02KOAPFyYvpfR
"""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

dataset=pd.read_csv("diabetes.csv")

dataset.head()

x=dataset.iloc[:,:-1].values
x

y=dataset.iloc[:,8].values

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

lda=LinearDiscriminantAnalysis(n_components=1,solver='eigen')

x_lda=lda.fit(x,y).transform(x)

model=lda.fit(x,y)
y_label=model.predict(x)

from sklearn.model_selection import train_test_split

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(x_lda,y_label,test_size = 0.3)

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors=5)
classifier.fit(X_train, Y_train)

print(classifier.score(X_test, Y_test))

############   PCA    ####################

from sklearn.decomposition import PCA
pca = PCA(n_components=1)
x_pca = pca.fit_transform(x)

x_train,x_test,y_train,y_test=train_test_split(x_pca,y,test_size=.3)
classifier = KNeighborsClassifier(n_neighbors=5)
classifier.fit(x_train, y_train)

print(classifier.score(x_test, y_test))

lda=pd.DataFrame(x_lda)
lda.to_csv("lda.csv")
lda_data=pd.read_csv("lda.csv")

pd.plotting.scatter_matrix(lda_data)

pca=pd.DataFrame(x_pca)
pca.to_csv("pca.csv")
pca_data=pd.read_csv("pca.csv")

pd.plotting.scatter_matrix(pca_data)

colors = ['red', 'blue']

for color, i, target_name in zip(colors, [0, 1], ['C1', 'C2']):
    plt.scatter(x[y == i, 0], x[y == i, 1], alpha=.8, color=color,
                label=target_name)
plt.legend(loc='best', shadow=False, scatterpoints=1)

plt.show()



colors = ['red', 'blue']

for color, i, target_name in zip(colors, [0, 1], ['C1', 'C2']):
    plt.scatter(x_pca[y == i, 0], x_pca[y == i, 0], alpha=.8, color=color,
                label=target_name)
plt.legend(loc='best', shadow=False, scatterpoints=1)

plt.show()

colors = ['red', 'blue']

for color, i, target_name in zip(colors, [0, 1], ['C1', 'C2']):
    plt.scatter(x_lda[y == i, 0], x_lda[y == i, 0], alpha=.8, color=color,
                label=target_name)
plt.legend(loc='best', shadow=False, scatterpoints=1)

plt.show()

from sklearn.linear_model import LogisticRegression

X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size = 0.3)

classifier = LogisticRegression()
classifier.fit(X_train, Y_train)

print(classifier.score(X_test, Y_test))

X_train, X_test, Y_train, Y_test = train_test_split(x_lda,y_label,test_size = 0.3)

classifier = LogisticRegression()
classifier.fit(X_train, Y_train)

print(classifier.score(X_test, Y_test))

from sklearn.tree import DecisionTreeClassifier

X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size = 0.3)

classifier = DecisionTreeClassifier(criterion='gini')
classifier.fit(X_train, Y_train)

print(classifier.score(X_test, Y_test))

X_train, X_test, Y_train, Y_test = train_test_split(x_lda,y_label,test_size = 0.3)

classifier = DecisionTreeClassifier(criterion='gini')
classifier.fit(X_train, Y_train)

print(classifier.score(X_test, Y_test))

####################################################################

from sklearn.neural_network import MLPClassifier
classifier = MLPClassifier(hidden_layer_sizes=(100), activation='identity')
classifier = classifier.fit(x,y)
predicted_label=classifier.predict(x)
print(accuracy_score(y,predicted_label))
classifier.n_layers_

classifier = MLPClassifier(hidden_layer_sizes=(200), activation='identity')
classifier = classifier.fit(x,y)
predicted_label=classifier.predict(x)
print(accuracy_score(y,predicted_label))
classifier.n_layers_

classifier = MLPClassifier(hidden_layer_sizes=(100), activation='relu')
classifier = classifier.fit(x,y)
predicted_label=classifier.predict(x)
print(accuracy_score(y,predicted_label))
classifier.n_layers_

classifier = MLPClassifier(hidden_layer_sizes=(200), activation='relu')
classifier = classifier.fit(x,y)
predicted_label=classifier.predict(x)
print(accuracy_score(y,predicted_label))
classifier.n_layers_

classifier = MLPClassifier(hidden_layer_sizes=(100), activation='tanh')
classifier = classifier.fit(x,y)
predicted_label=classifier.predict(x)
print(accuracy_score(y,predicted_label))
classifier.n_layers_

classifier = MLPClassifier(hidden_layer_sizes=(200), activation='tanh')
classifier = classifier.fit(x,y)
predicted_label=classifier.predict(x)
print(accuracy_score(y,predicted_label))
classifier.n_layers_

classifier = MLPClassifier(hidden_layer_sizes=(100), activation='logistic')
classifier = classifier.fit(x,y)
predicted_label=classifier.predict(x)
print(accuracy_score(y,predicted_label))
classifier.n_layers_

classifier = MLPClassifier(hidden_layer_sizes=(200), activation='logistic')
classifier = classifier.fit(x,y)
predicted_label=classifier.predict(x)
print(accuracy_score(y,predicted_label))
classifier.n_layers_

classifier = MLPClassifier(hidden_layer_sizes=(400), activation='tanh')
classifier = classifier.fit(x_lda,y_label)
predicted_label=classifier.predict(x_lda)
print(accuracy_score(y_label,predicted_label))
classifier.n_layers_

classifier = MLPClassifier(hidden_layer_sizes=(200), activation='logistic')
classifier = classifier.fit(x_lda,y_label)
predicted_label=classifier.predict(x_lda)
print(accuracy_score(y_label,predicted_label))
classifier.n_layers_


# -*- coding: utf-8 -*-
"""lab10ML (5).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bFppWdhIcEcGK36SDo6yw907LYSxv6Q8
"""

import pandas as pd

dataset=pd.read_csv("Iris.csv")

dataset

x= dataset.drop('Species', axis = 1)

y = dataset['Species']

len(x)

len(y)

from sklearn.preprocessing import LabelEncoder

encoder=LabelEncoder()

y=encoder.fit_transform(y)

y

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test=train_test_split(x,y,train_size=.7)

len(y_train)

len(x_train)

from sklearn.neural_network import MLPClassifier

for i in range(5):
  classifier = MLPClassifier(hidden_layer_sizes=2,learning_rate_init=((0.001)*(10**i)), max_iter=50, activation = 'relu')
  classifier = classifier.fit(x_train, y_train)
  classifier.predict_proba(x_test)
  classifier.predict(x_test)
  print("learning rate ", (0.001)*(10**i))
  print("accuracy",classifier.score(x_test, y_test))

score=[]
loss=[]

c=10
for i in range(10):
  classifier = MLPClassifier(hidden_layer_sizes=2,learning_rate_init=.1, max_iter=c, activation = 'relu')
  classifier = classifier.fit(x_train, y_train)
  classifier.predict_proba(x_test)
  classifier.predict(x_test)
  s = classifier.score(x_test, y_test)
  score.append(s)
  loss_values = classifier.loss_curve_
  loss.append(loss_values)
  c=c+10

import matplotlib.pyplot as plt

for i in range(10):
  print("learning rate value : ", (i+1)*10)
  print("accuracy score : ", score[i])
  plt.plot(loss[i])
  plt.show()

train_data=pd.read_csv("train.csv")
test_data=pd.read_csv("test.csv")

train_data

train_data.describe()

# print(train_data.isnull())

columns=train_data.loc[:, train_data.isnull().any()].columns
dropcolumns=['Alley','MiscFeature','PoolQC','Fence']

train_data = train_data.drop(dropcolumns,axis=1)#####dropping columns with insufficient information
test_data=test_data.drop(dropcolumns,axis=1)

numeric_columns = train_data.select_dtypes(['float','int']).columns
categoric_columns = train_data.select_dtypes('object').columns
numeric_columns2 = test_data.select_dtypes(['float','int']).columns
categoric_columns2 = test_data.select_dtypes('object').columns

import numpy as np
from sklearn.impute import SimpleImputer

df=train_data["LotFrontage"]
means=df.mean(skipna=True)
df1=test_data["LotFrontage"]
means=df1.mean(skipna=True)

train_data['LotFrontage'] = train_data['LotFrontage'].replace(np.nan, 70.04995836802665)
for i in numeric_columns:
  train_data[i] = train_data[i].replace(np.nan, 0)
for i in categoric_columns:
  train_data[i]=train_data[i].replace(np.nan,"NOTHING")

test_data['LotFrontage'] = test_data['LotFrontage'].replace(np.nan, 70.04995836802665)
for i in numeric_columns2:
  test_data[i] = test_data[i].replace(np.nan, 0)
for i in categoric_columns2:
  test_data[i]=test_data[i].replace(np.nan,"NOTHING")

train_data.info()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for feat in categoric_columns:
    train_data[feat] = le.fit_transform(train_data[feat].astype(str))
print (train_data.info())
# https://www.kaggle.com/learn-forum/61148
for feat in categoric_columns2:
    test_data[feat] = le.fit_transform(test_data[feat].astype(str))

train_data

test_data

y=train_data.iloc[:,-1]
X=train_data.iloc[:,1:76]
testinputs=test_data.iloc[:,1:76]

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3)

from sklearn.neural_network import MLPRegressor
model= MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.00001, batch_size='auto', learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=500)
model.fit(X_train, y_train)
y_predict = model.predict(X_test)
model.score(X_test,y_test)

predictions = pd.DataFrame(y_predict, dtype = float) 
print(predictions)

testinputs

y_pred=model.predict(testinputs)

y_pred

for i in range(4):
  print("predicted cost",y_pred[i])

test_labels=pd.read_csv("sample_submission.csv")

test=test_labels['SalePrice']
test

from sklearn.metrics import mean_squared_error
mean_squared_error(test,y_pred)

n = len(test)
manhattan = 0
for i in range(n):
  manhattan+=abs(test[i]-y_pred[i])

 
euclidean= 0
for i in range(n):
  euclidean+=((test[i]-y_pred[i])**2)
euclidean=euclidean**(0.5)
print("manhattan loss",manhattan)
print("euclidean loss",euclidean)

loss_values = model.loss_curve_
plt.plot(loss_values)
plt.show()

